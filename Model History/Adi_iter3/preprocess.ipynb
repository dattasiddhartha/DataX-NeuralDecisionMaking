{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and initialize directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "from scipy.io import loadmat\n",
    "import unittest\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "beh_dir = '../../data/decision-making/data/data_behav'\n",
    "neur_dir = '../../data/decision-making/data/data_ephys'\n",
    "preproc_dir = '../../data/decision-making/data/data_preproc'\n",
    "\n",
    "beh_files = [file for file in glob.glob(os.path.join(beh_dir,\"gamble.data*.csv\"))]\n",
    "neur_files = [file for file in glob.glob(os.path.join(neur_dir,\"*.mat\"))]\n",
    "\n",
    "sfreq = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create df where each row corresponds to 1 subject-electrode-trial = 1 example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/decision-making/data/data_behav/bad_trials_OFC.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/envs/data-x/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/decision-making/data/data_behav/bad_trials_OFC.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-018c7a4974ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read bad_trials, for exclusion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbad_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeh_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bad_trials_OFC.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bad_trials_OFC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# read game_model which, we hope, is identical across subjects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgame_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeh_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gamble_choices.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data-x/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \"\"\"\n\u001b[1;32m    140\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data-x/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[0;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data-x/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/decision-making/data/data_behav/bad_trials_OFC.mat'"
     ]
    }
   ],
   "source": [
    "# read bad_trials, for exclusion\n",
    "bad_trials = sio.loadmat(os.path.join(beh_dir, 'bad_trials_OFC.mat'))['bad_trials_OFC']\n",
    "\n",
    "# read game_model which, we hope, is identical across subjects\n",
    "game_model = pd.read_csv(os.path.join(beh_dir,'gamble_choices.csv'))\n",
    "\n",
    "# make master df where you append each subject's df\n",
    "df_master = pd.DataFrame(columns = ['subject', \n",
    "                                    'include.trial', \n",
    "                                    'round', \n",
    "                                    'newround.time', \n",
    "                                    'choice.time',\n",
    "                                    'buttonpress.time', \n",
    "                                    'conf.time', \n",
    "                                    'reveal.time', \n",
    "                                    'choice.class',\n",
    "                                    'choice.location', \n",
    "                                    'outcome', \n",
    "                                    'Safe.Bet.Amount', \n",
    "                                    'Risky.Bet.Amount',\n",
    "                                    'Risky.bet.shown.number', \n",
    "                                    'Risky.bet.hidden.number', \n",
    "                                    'Risky.Side',\n",
    "                                    'data', \n",
    "                                    'channel'])\n",
    "\n",
    "for sub_index, files in enumerate(zip(beh_files, neur_files)):\n",
    "    beh_file = files[0]\n",
    "    neur_file = files[1]\n",
    "    \n",
    "    print(sub_index)\n",
    "    print()\n",
    "    \n",
    "    ## Read data\n",
    "    # ------------------------------------------------------------------------------------------------------.\n",
    "    # behavior\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.read_csv(os.path.join(beh_file))\n",
    "    \n",
    "    # neural\n",
    "    neur = loadmat(neur_file)['buttonpress_events_hg']\n",
    "    \n",
    "    ## Number trials and number electrodes\n",
    "    # ------------------------------------------------------------------------------------------------------.\n",
    "    num_trials_beh = len(df)\n",
    "    \n",
    "    num_trials = neur.shape[0]\n",
    "    num_samples = neur.shape[1]\n",
    "    nchan = neur.shape[2]\n",
    "    \n",
    "    # add subject column on the left: make it be 1-indexed, corresponding to the subid's in the file\n",
    "    df.insert(0, 'subject', sub_index+1)\n",
    "    \n",
    "    ## Append game model data\n",
    "    # ------------------------------------------------------------------------------------------------------.\n",
    "    df = df.merge(game_model[:num_trials_beh], left_index=True, right_index=True)    \n",
    "\n",
    "    ## Exclude bad trials from entire df: Makes it easier to match with neural data\n",
    "    # ------------------------------------------------------------------------------------------------------.\n",
    "    df.insert(1, 'include.trial', (bad_trials[sub_index,:num_trials_beh]==0) & (df['choice.location']!='Timeout'))\n",
    "    # exclude trials (shorten df)\n",
    "    df = df[df['include.trial']]\n",
    "    \n",
    "    # create a new index that just counts up to the number of included trials, and corresponds to the neural data\n",
    "    df.insert(0, 'trial_index_subject', np.arange(num_trials))\n",
    "    df = df.set_index('trial_index_subject')\n",
    "    \n",
    "    ## Add neural data\n",
    "    # ------------------------------------------------------------------------------------------------------.\n",
    "    # initialize a data column, that will take a row of data subject-electrode-trial,\n",
    "    # so a 1d-array of the number of time points in the data\n",
    "    df = df.assign(data=None)\n",
    "    df = df.assign(channel=None)\n",
    "    df_subject = pd.DataFrame(columns = df.columns)\n",
    "    \n",
    "    # loop over electrodes\n",
    "    for this_chan in range(nchan):\n",
    "        # create a dataframe for this specific channel, containing the behavior data for this subject\n",
    "        df_chan = df.copy()\n",
    "        df_chan['channel'] = this_chan\n",
    "        # loop over trials\n",
    "        for this_trial in range(num_trials):\n",
    "            # insert data for each trial of df: the neural data for electrode 0, that trial\n",
    "            df_chan.at[this_trial, 'data'] = list(neur[this_trial,:,this_chan])\n",
    "        df_subject = df_subject.append(df_chan)\n",
    "    df_master = df_master.append(df_subject)\n",
    "    \n",
    "    df_master.insert(0, 'index', np.arange(len(df_master)))\n",
    "    df_master = df_master.set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include only gambles where first number is 5 or 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use = df_master[(df_master['Risky.bet.shown.number']==5) | (df_master['Risky.bet.shown.number']==6)]\n",
    "df_use.insert(0, 'index_use', np.arange(len(df_use)))\n",
    "df_use = df_use.set_index('index_use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5698814409484724"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df_use['choice.class']=='Gamble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a *separate* X-matrix, and separate y-labels, for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_first = 0\n",
    "sample_last = 950\n",
    "num_samples = sample_last-sample_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First subject only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = len(df_use)\n",
    "# # extract all the listed data into an array\n",
    "X = np.empty([num_examples,num_samples])\n",
    "\n",
    "for this_example in range(num_examples):\n",
    "    X[this_example,sample_first:sample_last] = np.asarray(df_use['data'][this_example])[sample_first:sample_last]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over subjects and store in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(215, 950)\n",
      "215\n",
      "2\n",
      "(282, 950)\n",
      "282\n",
      "3\n",
      "(2832, 950)\n",
      "2832\n",
      "4\n",
      "(150, 950)\n",
      "150\n",
      "5\n",
      "(2562, 950)\n",
      "2562\n",
      "6\n",
      "(322, 950)\n",
      "322\n",
      "7\n",
      "(473, 950)\n",
      "473\n",
      "8\n",
      "(480, 950)\n",
      "480\n",
      "9\n",
      "(912, 950)\n",
      "912\n",
      "10\n",
      "(544, 950)\n",
      "544\n"
     ]
    }
   ],
   "source": [
    "subjects = set(df_use['subject'])\n",
    "\n",
    "Xdict = dict()\n",
    "ydict = dict()\n",
    "\n",
    "for this_subject in subjects:\n",
    "#     print(this_subject)\n",
    "    df_subject = df_use[df_use['subject']==this_subject]\n",
    "    num_examples = len(df_subject)\n",
    "    X = np.empty([num_examples,num_samples])\n",
    "\n",
    "    for this_example in range(num_examples):\n",
    "        X[this_example,sample_first:sample_last] = np.asarray(df_use['data'][this_example])[sample_first:sample_last]\n",
    "#     print(X.shape)\n",
    "    Xdict[this_subject] = X\n",
    "    ydict[this_subject] = df_subject['choice.class'].values\n",
    "#     print(len(ydict[this_subject]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save X and y dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','Xdict.pickle'), 'wb') as handle1:\n",
    "    pickle.dump(Xdict, handle1, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','ydict.pickle'), 'wb') as handle2:\n",
    "    pickle.dump(ydict, handle2, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Xdict.pickle', 'ydict.pickle']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
